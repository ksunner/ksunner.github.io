<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>EE106A Final Project: Autonomous Chess Player | UC Berkeley</title>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <!-- Prism.js for syntax highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
  
  <style>
    :root {
      --bg: #ffffff;
      --text: #0f172a;
      --muted: #475569;
      --border: #e2e8f0;
      --subtle: #f8fafc;
      --accent: #2563eb;
      --code: #f6f8fa;
    }
    * { box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body {
      margin: 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      line-height: 1.6;
      color: var(--text);
      background: var(--bg);
    }
    .wrap { max-width: 1200px; margin: 0 auto; padding: 24px 16px; }
    header.wrap { padding-top: 32px; padding-bottom: 8px; }
    .header-row { display: flex; align-items: center; justify-content: space-between; gap: 16px; flex-wrap: wrap; }
    h1 { font-size: 1.9rem; margin: 0 0 4px; letter-spacing: -0.02em; }
    .meta { color: var(--muted); font-size: 0.95rem; }
    .badge { display: inline-block; padding: 6px 12px; border-radius: 999px; border: 1px solid var(--border); color: var(--muted); text-decoration: none; font-size: 0.9rem; }
    .badge:hover { background: var(--subtle); border-color: var(--accent); color: var(--accent); }

    .grid { display: grid; grid-template-columns: 220px 1fr; gap: 24px; }
    @media (max-width: 900px) { .grid { grid-template-columns: 1fr; } }

    aside { position: sticky; top: 16px; align-self: start; background: #fff; border: 1px solid var(--border); border-radius: 12px; padding: 16px; }
    aside h2 { font-size: 0.85rem; margin: 0 0 8px; letter-spacing: 0.05em; color: var(--muted); text-transform: uppercase; }
    nav a { display: block; padding: 6px 10px; border-radius: 8px; color: var(--text); text-decoration: none; font-size: 0.9rem; }
    nav a:hover { background: var(--subtle); }
    nav a.active { background: #eef2ff; border: 1px solid #c7d2fe; }
    @media (max-width: 900px) { aside { position: static; } }

    main section { padding: 24px; border: 1px solid var(--border); border-radius: 12px; background: #fff; margin-bottom: 24px; }
    section h2 { margin-top: 0; font-size: 1.35rem; }
    section h3 { margin-top: 1.5em; font-size: 1.1rem; }
    section h4 { margin-top: 1.2em; font-size: 1rem; color: var(--muted); }

    .callout { background: var(--subtle); border-left: 4px solid var(--accent); padding: 12px 16px; border-radius: 0 10px 10px 0; margin: 16px 0; }
    .callout-warning { background: #fffbeb; border-left-color: #f59e0b; }
    .callout-success { background: #f0fdf4; border-left-color: #22c55e; }

    .figure-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: 16px; margin: 16px 0; }
    @media (max-width: 700px) { .figure-grid { grid-template-columns: 1fr; } }
    .figure-grid-3 { grid-template-columns: repeat(3, 1fr); }
    @media (max-width: 900px) { .figure-grid-3 { grid-template-columns: repeat(2, 1fr); } }
    @media (max-width: 600px) { .figure-grid-3 { grid-template-columns: 1fr; } }
    figure { margin: 0; border: 1px solid var(--border); border-radius: 12px; overflow: hidden; background: #fff; }
    figure img { width: 100%; display: block; }
    figure .placeholder { 
      aspect-ratio: 16/10; 
      background: linear-gradient(135deg, #f1f5f9 0%, #e2e8f0 100%); 
      display: flex; 
      align-items: center; 
      justify-content: center; 
      color: var(--muted);
      font-size: 0.9rem;
    }
    figcaption { padding: 10px 12px; color: var(--muted); font-size: 0.88rem; border-top: 1px solid var(--border); }

    table { width: 100%; border-collapse: collapse; margin: 16px 0; font-size: 0.92rem; }
    th, td { border: 1px solid var(--border); padding: 10px 12px; text-align: left; }
    th { background: var(--subtle); font-weight: 600; }
    .table-wrap { overflow-x: auto; }

    code { background: var(--code); padding: 2px 6px; border-radius: 4px; font-size: 0.9em; font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, monospace; }
    pre, pre[class*="language-"] { background: #2d3748; color: #e2e8f0; padding: 16px; border-radius: 10px; overflow-x: auto; font-size: 0.85rem; line-height: 1.5; margin: 0; }
    pre code, pre[class*="language-"] code { background: none; padding: 0; font-size: inherit; color: inherit; }
    .code-header { background: #1a202c; color: #a0aec0; padding: 8px 16px; border-radius: 10px 10px 0 0; font-size: 0.8rem; font-family: ui-monospace, monospace; display: flex; justify-content: space-between; }
    .code-header + pre, .code-header + pre[class*="language-"] { border-radius: 0 0 10px 10px; margin-top: 0; }
    
    /* Prism.js token colors for better visibility */
    .token.comment, .token.prolog, .token.doctype, .token.cdata { color: #68d391; }
    .token.punctuation { color: #e2e8f0; }
    .token.property, .token.tag, .token.boolean, .token.number, .token.constant, .token.symbol { color: #f6ad55; }
    .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin { color: #68d391; }
    .token.operator, .token.entity, .token.url { color: #63b3ed; }
    .token.atrule, .token.attr-value, .token.keyword { color: #b794f4; }
    .token.function { color: #63b3ed; }
    .token.class-name { color: #faf089; }
    .token.regex, .token.important, .token.variable { color: #fc8181; }

    .small { color: var(--muted); font-size: 0.9rem; }

    .metrics-row { display: grid; grid-template-columns: repeat(4, 1fr); gap: 12px; margin: 20px 0; }
    @media (max-width: 700px) { .metrics-row { grid-template-columns: repeat(2, 1fr); } }
    .metric { background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%); color: white; padding: 16px; border-radius: 10px; text-align: center; }
    .metric .value { font-size: 1.8rem; font-weight: 700; }
    .metric .label { font-size: 0.85rem; opacity: 0.9; }

    .team-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 16px; margin: 16px 0; }
    .team-card { border: 1px solid var(--border); border-radius: 12px; padding: 20px; text-align: center; background: #fff; }
    .team-card .avatar { width: 60px; height: 60px; border-radius: 50%; background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%); margin: 0 auto 12px; display: flex; align-items: center; justify-content: center; color: white; font-size: 1.5rem; }
    .team-card h4 { margin: 0 0 4px; font-size: 1rem; }
    .team-card .role { color: var(--accent); font-size: 0.85rem; font-weight: 500; }
    .team-card p { color: var(--muted); font-size: 0.85rem; margin: 8px 0 0; }

    .links-row { display: grid; grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 12px; margin: 16px 0; }
    .link-card { border: 1px solid var(--border); border-radius: 10px; padding: 16px; text-align: center; text-decoration: none; color: inherit; transition: all 0.2s; }
    .link-card:hover { border-color: var(--accent); background: #f8fafc; }
    .link-card .icon { font-size: 1.5rem; margin-bottom: 6px; }
    .link-card h5 { margin: 0; font-size: 0.95rem; }
    .link-card p { margin: 4px 0 0; font-size: 0.8rem; color: var(--muted); }

    .flow-steps { display: flex; flex-wrap: nowrap; align-items: center; gap: 6px; margin: 16px 0; overflow-x: auto; padding-bottom: 4px; }
    .flow-step { background: white; border: 2px solid var(--accent); padding: 6px 10px; border-radius: 8px; font-size: 0.78rem; font-weight: 500; white-space: nowrap; }
    .flow-arrow { color: var(--accent); font-weight: bold; font-size: 0.85rem; }

    .file-tree { background: #1e293b; color: #e2e8f0; padding: 16px; border-radius: 10px; font-family: ui-monospace, monospace; font-size: 0.82rem; line-height: 1.7; overflow-x: auto; }
    .file-tree .folder { color: #fbbf24; }
    .file-tree .file { color: #60a5fa; }
    .file-tree .comment { color: #64748b; }

    ul, ol { padding-left: 24px; }
    li { margin-bottom: 6px; }

    footer { text-align: center; color: var(--muted); font-size: 0.9rem; padding: 24px 0 48px; }
    footer a { color: var(--accent); text-decoration: none; }
  </style>
</head>
<body>
  <header class="wrap">
    <div class="header-row">
      <div>
        <h1>EE106A Final Project: Autonomous Chess Player</h1>
        <div class="meta">Karanbir Sunner, Maanit Sharma, Faiaz Khan, Pranav Banwasi · UC Berkeley · Fall 2025</div>
      </div>
      <a class="badge" href="https://github.com/ksunner/ee106a-final-project/tree/working_chess" target="_blank">GitHub →</a>
    </div>
  </header>

  <div class="wrap grid">
    <aside aria-label="Table of contents">
      <h2>Contents</h2>
      <nav id="toc">
        <a href="#overview">Overview</a>
        <a href="#experimentation">Experimentation</a>
        <a href="#design">Design</a>
        <a href="#implementation">Implementation</a>
        <a href="#results">Results</a>
        <a href="#conclusion">Conclusion</a>
        <a href="#team">Team</a>
        <a href="#materials">Materials</a>
      </nav>
    </aside>

    <main>
      <!-- OVERVIEW -->
      <section id="overview">
        <h2>Overview</h2>
        <p>
          We present a fully autonomous robotic chess-playing system that integrates computer vision, motion planning, 
          and real-time control. Our system uses a <strong>UR7e robotic arm</strong> equipped with a parallel-jaw gripper 
          to physically manipulate chess pieces on a standard board.
        </p>
        <p>
          Previous implementations of autonomous chess players often required meticulous placement of ArUco markers on 
          every single piece, making setup tedious and not user-friendly. We wanted to generalize this process significantly.
        </p>
        <p>
          Our key innovation is an <strong>ArUco marker-based calibration system</strong> that uses bilinear interpolation 
          to compute precise 3D positions for all 64 squares from just <strong>4 corner markers</strong>. This eliminates 
          the need for per-piece markers, removes rigid camera mounting requirements, and enables rapid recalibration when the board moves.
        </p>
        <div class="callout">
          <strong>Key Results:</strong> The system successfully executed <strong>30+ consecutive moves</strong> without 
          human intervention or robot crashes, demonstrating the viability of vision-guided manipulation for structured tabletop tasks.
        </div>

        <h3>Project Goals</h3>
        <p>Given a chess move (e.g., "e2 to e4"), the robot must:</p>
        <ol>
          <li>Locate the source square on the physical board</li>
          <li>Navigate to and grasp the piece without disturbing neighbors</li>
          <li>Transport the piece through free space avoiding collisions</li>
          <li>Place it precisely on the destination square</li>
          <li>Retreat safely for the next move</li>
        </ol>
        <p>Additionally, the system should:</p>
        <ul>
          <li><strong>Easy Setup:</strong> Minimal calibration required to get the system running</li>
          <li><strong>Game Replay:</strong> Allow users to replay many moves in sequence from game files</li>
        </ul>

        <h3>Real-World Applications</h3>
        <p>
          The techniques developed in this project extend beyond chess to a variety of real-world robotics applications:
        </p>
        <ul>
          <li><strong>Warehouse Automation:</strong> Pick-and-place of items in structured grid layouts (shelves, bins)</li>
          <li><strong>Manufacturing Assembly:</strong> Precise component placement on circuit boards or assembly lines</li>
          <li><strong>Laboratory Automation:</strong> Handling samples in well plates or test tube racks</li>
          <li><strong>Food Service:</strong> Automated plating or ingredient placement in commercial kitchens</li>
          <li><strong>Assistive Robotics:</strong> Helping users with limited mobility interact with board games or physical tasks</li>
        </ul>

        <h3>Why Chess is Challenging</h3>
        <p>
          Each move must be precise. Small errors can cascade into large errors across long games, making consistency and repeatability critical for autonomous play.
        </p>
        <ul>
          <li><strong>Dense Environment:</strong> 32 pieces on 64 squares, pieces separated by only ~5.5cm</li>
          <li><strong>Error Accumulation:</strong> Slight misplacements compound over many moves, eventually causing failures</li>
          <li><strong>Occlusion:</strong> Robot arm can block camera view during manipulation</li>
          <li><strong>Sequential Constraints:</strong> Each move requires a complete approach-grasp-lift-move-place-retreat cycle</li>
        </ul>
      </section>

      <!-- EXPERIMENTATION -->
      <section id="experimentation">
        <h2>Experimentation</h2>
        <p>
          Before arriving at our final autonomous chess player design, we explored several approaches for vision-based pick-and-place. This experimentation was crucial: the ArUco localization techniques we developed during this phase became the foundation for our chess system.
        </p>

        <h3>Initial Goal: Color Block Sorter</h3>
        <p>
          Our original project aimed to create a pick-and-place pipeline that could automatically sort colored objects using the UR7e. We explored two distinct approaches before pivoting to the chess application.
        </p>

        <h4>Approach 1: Intel RealSense + HSV Detection</h4>
        <p>
          Our first approach used the Intel RealSense depth camera with HSV color segmentation to detect and localize colored objects. We combined YOLO object detection with HSV filtering to automatically identify cube poses without manual plane specification.
        </p>

        <div class="callout">
          <strong>Key Achievement:</strong> Successfully detected distinct poses for red and blue objects, then executed pick-and-place to sort them to different sides of the workspace.
        </div>

        <div class="code-header"><span>HSV Color Filtering - Blue Detection</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def filter_blue_color(self, colors: np.ndarray) -> np.ndarray:
    """Filter for blue colors using HSV color space."""
    # Normalize RGB to [0, 1] and convert to HSV
    colors_normalized = colors / 255.0
    r, g, b = colors_normalized[:, 0], colors_normalized[:, 1], colors_normalized[:, 2]
    
    max_c = np.maximum(np.maximum(r, g), b)
    min_c = np.minimum(np.minimum(r, g), b)
    diff = max_c - min_c

    # Calculate Hue
    h = np.zeros_like(max_c)
    mask_b = (max_c == b) & (diff > 0)
    h[mask_b] = 60 * (((r[mask_b] - g[mask_b]) / diff[mask_b]) + 4)

    # Calculate Saturation and Value
    s = np.where(max_c > 0, diff / max_c, 0)
    v = max_c

    # Blue hue range: 180-260 degrees
    blue_mask = (h >= 180) & (h <= 260) & (s >= 0.3) & (v >= 0.2)
    return blue_mask</code></pre>

        <p>
          <strong>Limitation:</strong> We were informed that our group was not allocated a RealSense camera, forcing us to pivot to a standard webcam which lacked depth estimation capabilities.
        </p>

        <h4>Approach 2: Webcam + ArUco Localization</h4>
        <p>
          Without depth data, we needed a new localization strategy. Inspired by Lab 4's TurtleBot localization, we attached ArUco markers to each colored cube. The key challenge was transforming marker poses from the camera frame to the robot's <code>base_link</code> frame.
        </p>

        <figure>
          <img src="images/tf_tree.png" alt="TF Tree showing transform chain" style="width: 100%; border-radius: 8px;">
          <figcaption>Successfully linked ArUco markers poses in TF tree!</figcaption>
        </figure>

        <p>
          By publishing a static transform between the robot's ArUco marker and <code>base_link</code>, we could compute any object's position relative to the robot. This enabled the same IK-based motion planning we had developed for the RealSense approach.
        </p>

        <div class="code-header"><span>Terminal - Running the Color Sorter</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Launch the multi-cube detection system
ros2 launch planning multi_cube_pick_place.launch.py

# Sort cubes by color to different directions
ros2 run planning main --color blue --direction right
ros2 run planning main --color green --direction left
ros2 run planning main --color red --direction front</code></pre>

        <h3>Cube Pickup Demo</h3>
        <figure>
          <iframe width="100%" style="aspect-ratio: 16/9;" src="https://www.youtube.com/embed/kWdGzFx-SrI?rel=0" title="Gripper Picking Up Cubes" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          <figcaption>Demonstration of the gripper picking up colored cubes</figcaption>
        </figure>

        <h3>Key Insights → Chess Application</h3>
        <p>
          While we successfully implemented the color sorter, we realized the ArUco localization system we built had broader applications. The techniques we developed became the foundation for our chess player:
        </p>

        <div class="table-wrap">
          <table>
            <thead>
              <tr><th>Color Sorter Technique</th><th>Chess Player Application</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>ArUco marker → base_link transform</td>
                <td>Corner markers define board position relative to robot</td>
              </tr>
              <tr>
                <td>Sequential job queue for pick-and-place</td>
                <td>8-step and 16-step move sequences</td>
              </tr>
              <tr>
                <td>Real-time IK computation</td>
                <td>On-the-fly trajectory planning for any square</td>
              </tr>
              <tr>
                <td>Pre-grasp → grasp → lift → place pattern</td>
                <td>Vertical approach strategy for dense piece environments</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="callout callout-success">
          <strong>Pivot Decision:</strong> The ArUco-based localization proved so robust that we decided to extend it to a more challenging application: autonomous chess playing, where precision and repeatability are critical.
        </div>
      </section>

      <!-- DESIGN -->
      <section id="design">
        <h2>Design</h2>
        
        <h3>Design Criteria</h3>
        <div class="table-wrap">
          <table>
            <thead>
              <tr><th>Criterion</th><th>Rationale</th></tr>
            </thead>
            <tbody>
              <tr><td>Placement Accuracy</td><td>Pieces must land clearly within square boundaries; ambiguous placements can confuse players or invalidate moves</td></tr>
              <tr><td>Collision Avoidance</td><td>Toppling even one piece invalidates the game state and requires manual intervention to restore</td></tr>
              <tr><td>Calibration Time</td><td>Users should be able to set up and start playing quickly without lengthy calibration procedures</td></tr>
              <tr><td>Move Execution</td><td>Moves should complete in a reasonable time to maintain natural game flow and user engagement</td></tr>
              <tr><td>Success Rate</td><td>The system must be reliable enough to complete full games (30+ moves) without failures</td></tr>
            </tbody>
          </table>
        </div>

        <h3>System Architecture</h3>
        <p>We chose a modular ROS2 architecture with clear separation of concerns. Each component communicates via ROS2 topics, services, and the TF tree:</p>
        
        <h4>Perception Layer</h4>
        <p>Handles all vision and localization tasks:</p>
        <ul>
          <li><strong>ArucoNode:</strong> Detects ArUco markers from the camera feed and publishes their poses as TF transforms</li>
          <li><strong>ChessBoardCalibrator:</strong> Listens to corner marker transforms, computes all 64 square positions via bilinear interpolation, and publishes each square's position to <code>/chess_square/{a1-h8}</code></li>
          <li><strong>Static TF Publisher:</strong> Defines the fixed transform between the robot's base ArUco marker and <code>base_link</code></li>
        </ul>

        <h4>Planning Layer</h4>
        <p>Converts high-level move commands into executable trajectories:</p>
        <ul>
          <li><strong>ChessMove / ChessTake:</strong> Accepts source and destination squares, subscribes to their positions, and builds the 8-step or 16-step job queue</li>
          <li><strong>ChessGameReplay:</strong> Parses game files and sequences multiple moves with configurable delays</li>
          <li><strong>IKPlanner:</strong> Interfaces with MoveIt2 to compute inverse kinematics and generate collision-free joint trajectories</li>
        </ul>

        <h4>Control Layer</h4>
        <p>Executes physical robot actions:</p>
        <ul>
          <li><strong>Trajectory Controller:</strong> Receives joint trajectories via the <code>FollowJointTrajectory</code> action and executes them on the UR7e</li>
          <li><strong>Gripper Service:</strong> Toggles the parallel-jaw gripper open/closed via <code>/toggle_gripper</code></li>
        </ul>

        <h4>Data Flow</h4>
        <div class="callout">
          <strong>Move Execution Pipeline:</strong><br>
          Camera → ArucoNode → TF Tree → ChessBoardCalibrator → Square Positions → ChessMove → IKPlanner → Trajectory Controller → UR7e
        </div>

        <h3>Key Design Choices</h3>
        
        <h4>1. ArUco Markers vs. Chessboard Pattern Detection</h4>
        <p><strong>Decision:</strong> Use 4 ArUco markers at board corners instead of detecting the chessboard pattern.</p>
        <ul>
          <li><strong>Pro:</strong> Unique IDs enable unambiguous corner identification even under partial occlusion</li>
          <li><strong>Pro:</strong> Works with any board design (not just alternating colors)</li>
          <li><strong>Con:</strong> Requires physical markers attached to the board</li>
        </ul>
        <p><strong>Alternatives Explored:</strong></p>
        <ul>
          <li><strong>Single center marker:</strong> We initially tried using just one ArUco marker in the center of the board, but this was abandoned because slight misplacements or detection errors would throw off calculations for the entire board. With 4 corner markers, errors are localized and the interpolation remains accurate.</li>
          <li><strong>No markers on board:</strong> We also experimented with marker-free approaches (e.g., detecting the chessboard pattern directly), but this proved too difficult with minimal upside. Lighting variations and board designs made reliable detection inconsistent.</li>
          <li><strong>Markers on pieces:</strong> We considered placing ArUco markers on the pieces themselves. While this did work for detection, the irregular geometry of chess pieces (especially knights, bishops, and kings) made it difficult to stably attach markers. Markers would shift or fall off during grasping, making this approach unreliable.</li>
        </ul>

        <h4>2. Bilinear Interpolation vs. Homography</h4>
        <p><strong>Decision:</strong> Compute square positions using 3D bilinear interpolation from corner markers.</p>
        <ul>
          <li><strong>Pro:</strong> Handles 3D positions naturally (including Z-height variations)</li>
          <li><strong>Pro:</strong> Gracefully handles slight board warping</li>
          <li><strong>Pro:</strong> Computationally simple, single matrix operation</li>
        </ul>

        <h4>3. Vertical Approach Strategy</h4>
        <p><strong>Decision:</strong> The gripper always approaches pieces from directly above (vertical descent).</p>
        <ul>
          <li><strong>Pro:</strong> Minimizes risk of colliding with neighboring pieces</li>
          <li><strong>Pro:</strong> Simplifies IK constraints (fixed end-effector orientation)</li>
          <li><strong>Con:</strong> Requires sufficient vertical clearance; may be slower than diagonal approaches</li>
        </ul>
      </section>

      <!-- IMPLEMENTATION -->
      <section id="implementation">
        <h2>Implementation</h2>
        <p>
          This section provides a detailed walkthrough of our system's implementation, including the key ROS2 nodes,
          algorithms, and code that make autonomous chess playing possible.
        </p>

        <h3>ArUco Marker Detection</h3>
        <p>
          The <code>ArucoNode</code> is the foundation of our perception system. It detects the 4 corner markers on the chessboard (IDs 100-103) and 1 marker on the robot base, publishing their poses as TF transforms. This enables downstream nodes to query marker positions in the robot's coordinate frame.
        </p>

        <div class="code-header"><span>aruco_node.py - Marker Detection Node</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ArucoNode(rclpy.node.Node):
    def __init__(self):
        super().__init__("aruco_node")

        # Declare parameters for marker size, dictionary, and camera topics
        self.declare_parameter(name="marker_size", value=0.0625, ...)
        self.declare_parameter(name="aruco_dictionary_id", value="DICT_5X5_250", ...)
        self.declare_parameter(name="image_topic", value="/camera/image_raw", ...)
        self.declare_parameter(name="camera_info_topic", value="/camera/camera_info", ...)
        self.declare_parameter(name="camera_frame", value="", ...)

        # Load parameters
        self.marker_size = self.get_parameter("marker_size").value
        dictionary_name = self.get_parameter("aruco_dictionary_id").value
        ...

        # Marker sizes for specific tags (meters)
        # IDs 100-103: Chess board corners (5cm markers)
        # ID 5: Robot base marker
        self.marker_size_map = {
            1: 0.15,  2: 0.15,  3: 0.15,  4: 0.15,
            5: 0.05,
            6: 0.15, 7: 0.15, 8: 0.04, 9: 0.15,
            10: 0.15, 11: 0.15,
            20: 0.05, 21: 0.05, 22: 0.05,
            100: 0.05, 101: 0.05, 102: 0.05, 103: 0.05  # Board corners
        }

        # Initialize ArUco detector (OpenCV >= 4.7)
        self.aruco_dictionary = cv2.aruco.getPredefinedDictionary(dictionary_id)
        self.aruco_parameters = cv2.aruco.DetectorParameters()
        self.detector = cv2.aruco.ArucoDetector(
            self.aruco_dictionary, self.aruco_parameters
        )

        # Subscribe to camera feed
        self.info_sub = self.create_subscription(
            CameraInfo, info_topic, self.info_callback, qos_profile_sensor_data)
        self.create_subscription(
            Image, image_topic, self.image_callback, qos_profile_sensor_data)

        # Publish detected marker poses
        self.poses_pub = self.create_publisher(PoseArray, "aruco_poses", 10)
        self.markers_pub = self.create_publisher(ArucoMarkers, "aruco_markers", 10)

        # Broadcast marker poses as TF transforms
        self.tf_broadcaster = TransformBroadcaster(self)

        self.bridge = CvBridge()
        self.info_msg = None
        self.intrinsic_mat = None
        self.distortion = None</code></pre>

        <p>
          <strong>Key points:</strong> The <code>marker_size_map</code> dictionary maps each marker ID to its physical size, which is critical for accurate pose estimation. The node uses OpenCV's modern ArUco API and broadcasts each detected marker's pose to the TF tree, making positions available to all other nodes.
        </p>

        <h3>Chess Board Calibration</h3>
        <p>
          Once the ArUco markers are detected, the <code>ChessBoardCalibrator</code> node computes the 3D position of all 64 square centers. It uses the 4 corner markers (IDs 100-103) placed at squares a1, h1, h8, and a8, then applies <strong>bilinear interpolation</strong> to calculate every square's position in the robot's coordinate frame.
        </p>

        <div class="code-header"><span>chess_board_calibrator.py - Node Initialization</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ChessBoardCalibrator(Node):
    """
    Calibrates chess board using ArUco markers at corners.
    
    Markers are placed at:
    - 100: a1 (bottom-left)
    - 101: h1 (bottom-right)
    - 102: h8 (top-right)
    - 103: a8 (top-left)
    """

    def __init__(self):
        super().__init__('chess_board_calibrator')

        # ArUco marker IDs at corners
        self.marker_ids = {
            'a1': 100, 'h1': 101, 'h8': 102, 'a8': 103
        }

        self.marker_positions = {}    # Detected marker positions
        self.calibrated = False
        self.square_centers = {}      # Maps square notation to (x, y, z)

        # Calibration persisted to file for quick startup
        self.calibration_file = Path.home() / '.ros' / 'chess_calibration.yaml'
        ...

        # TF listener to get marker positions from aruco_node
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # Publishers
        self.board_center_pub = self.create_publisher(
            PointStamped, '/chess_board_center', 10)
        self.square_pubs = {}  # Created dynamically for each square

        # Service to trigger calibration
        self.calibration_service = self.create_service(
            Trigger, '/calibrate_chess_board', self.calibrate_callback)

        # Timer to continuously lookup markers until calibrated
        self.timer = self.create_timer(0.1, self.lookup_markers)

        # Try to load previous calibration on startup
        if self.load_calibration():
            self.get_logger().info("Loaded previous calibration from file")
            self.create_timer(0.1, self.publish_all_squares)</code></pre>

        <h4>Marker Lookup via TF</h4>
        <p>
          The node continuously queries the TF tree for each corner marker's position relative to the robot's <code>base_link</code>. Once all 4 markers are found, calibration can proceed.
        </p>

        <div class="code-header"><span>chess_board_calibrator.py - TF Lookup</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def lookup_markers(self):
    """Continuously lookup marker positions via TF."""
    if self.calibrated:
        return  # Stop looking once calibrated

    base_frame = "base_link"

    for square, marker_id in self.marker_ids.items():
        ar_frame = f"ar_marker_{marker_id}"

        try:
            t = self.tf_buffer.lookup_transform(
                base_frame, ar_frame,
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=1.0)
            )

            # Store position as numpy array
            pos = np.array([
                t.transform.translation.x,
                t.transform.translation.y,
                t.transform.translation.z
            ])
            self.marker_positions[square] = pos

        except Exception as e:
            continue  # Marker not yet visible</code></pre>

        <h4>Bilinear Interpolation</h4>
        <p>
          The core algorithm uses <strong>bilinear interpolation</strong> to compute all 64 square centers from just 4 corner positions. This works by treating the chessboard as a 2D grid where each square's position is a weighted blend of the four corners.
        </p>

        <div class="callout">
          <strong>How Bilinear Interpolation Works:</strong><br>
          For any square at file index <em>i</em> (0-7, a-h) and rank index <em>j</em> (0-7, 1-8), we compute normalized coordinates:
          <ul style="margin-bottom: 0;">
            <li><strong>u = i / 7</strong>: ranges from 0 (a-file) to 1 (h-file)</li>
            <li><strong>v = j / 7</strong>: ranges from 0 (rank 1) to 1 (rank 8)</li>
          </ul>
          The position is then: <code>P(u,v) = (1-u)(1-v)·a1 + u(1-v)·h1 + uv·h8 + (1-u)v·a8</code><br>
          Each corner contributes based on how "close" the square is to that corner. For example, square <strong>e4</strong> (i=4, j=3) has u≈0.57 and v≈0.43, so it's weighted roughly equally from all corners with slight bias toward h1.
        </div>

        <div class="code-header"><span>chess_board_calibrator.py - Bilinear Interpolation</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def calibrate_board(self):
    """
    Calibrate the board using the 4 corner markers.
    Computes all 64 square centers via bilinear interpolation.
    """
    try:
        # Get corner positions (numpy arrays)
        a1 = self.marker_positions['a1']  # Bottom-left
        h1 = self.marker_positions['h1']  # Bottom-right
        h8 = self.marker_positions['h8']  # Top-right
        a8 = self.marker_positions['a8']  # Top-left

        files = 'abcdefgh'
        ranks = '12345678'

        for file_idx, file_char in enumerate(files):
            for rank_idx, rank_char in enumerate(ranks):
                # Normalized interpolation parameters
                u = file_idx / 7.0  # 0 at 'a', 1 at 'h'
                v = rank_idx / 7.0  # 0 at '1', 1 at '8'

                # Bilinear interpolation formula
                pos = (
                    (1-u) * (1-v) * a1 +  # a1 weight
                    u * (1-v) * h1 +       # h1 weight
                    u * v * h8 +           # h8 weight
                    (1-u) * v * a8         # a8 weight
                )

                square = f"{file_char}{rank_char}"
                self.square_centers[square] = pos

        self.calibrated = True
        return True

    except Exception as e:
        self.get_logger().error(f"Calibration error: {str(e)}")
        return False</code></pre>

        <h4>Publishing Square Positions</h4>
        <p>
          After calibration, the node publishes each square's position on its own topic (e.g., <code>/chess_square/e4</code>). This allows any other node to subscribe to specific squares they need, enabling loose coupling between components.
        </p>

        <div class="code-header"><span>chess_board_calibrator.py - Position Publishing</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def publish_all_squares(self):
    """Publish all square positions continuously."""
    if not self.calibrated:
        return

    for square, pos in self.square_centers.items():
        # Create publisher for this square if it doesn't exist
        if square not in self.square_pubs:
            topic_name = f'/chess_square/{square}'
            self.square_pubs[square] = self.create_publisher(
                PointStamped, topic_name, 10)

        # Publish position
        msg = PointStamped()
        msg.header.frame_id = "base_link"
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.point.x = float(pos[0])
        msg.point.y = float(pos[1])
        msg.point.z = float(pos[2])

        self.square_pubs[square].publish(msg)</code></pre>

        <h4>Persistent Calibration</h4>
        <p>
          Calibration data is saved to <code>~/.ros/chess_calibration.yaml</code> so the system can start immediately without re-detecting markers. The calibration service <code>/calibrate_chess_board</code> can be called to force a fresh calibration when the board moves.
        </p>

        <div class="code-header"><span>chess_board_calibrator.py - Save/Load Calibration</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def save_calibration(self):
    """Save calibration data to YAML file."""
    data = {
        'square_centers': {
            square: pos.tolist()  # Convert numpy to list
            for square, pos in self.square_centers.items()
        }
    }
    with open(self.calibration_file, 'w') as f:
        yaml.dump(data, f, default_flow_style=False)
    return True

def load_calibration(self):
    """Load calibration data from YAML file."""
    if not self.calibration_file.exists():
        return False

    with open(self.calibration_file, 'r') as f:
        data = yaml.safe_load(f)

    # Convert lists back to numpy arrays
    self.square_centers = {
        square: np.array(pos)
        for square, pos in data['square_centers'].items()
    }
    self.calibrated = True
    return True</code></pre>

        <div class="callout callout-success">
          <strong>Published Topics:</strong>
          <ul style="margin-bottom: 0;">
            <li><code>/chess_board_center</code>: Center of the board (average of d4, d5, e4, e5)</li>
            <li><code>/chess_square/{a1-h8}</code>: 64 individual topics, one per square</li>
          </ul>
          <strong>Services:</strong>
          <ul style="margin-bottom: 0;">
            <li><code>/calibrate_chess_board</code>: Triggers fresh calibration (std_srvs/Trigger)</li>
          </ul>
        </div>

        <h3>Move Execution</h3>
        <p>
          With the board calibrated, we can command the robot to move pieces. The <code>ChessMove</code> node accepts a source and destination square via command line arguments, then executes an <strong>8-step atomic movement sequence</strong> to safely pick up and place the piece.
        </p>

        <div class="code-header"><span>Terminal - Running a Move</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Move a piece from e2 to e4
ros2 run planning chess_move --from e2 --to e4</code></pre>

        <h4>The 8-Step Movement Sequence</h4>
        <p>
          Each move follows a carefully designed sequence to avoid collisions with neighboring pieces. The robot always approaches from directly above (vertical descent) to minimize the risk of knocking over adjacent pieces.
        </p>

        <div class="flow-steps">
          <span class="flow-step">1. Approach</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">2. Descend</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">3. Grasp</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">4. Lift</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">5. Transit</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">6. Lower</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">7. Release</span>
          <span class="flow-arrow">→</span>
          <span class="flow-step">8. Retreat</span>
        </div>

        <div class="callout">
          <strong>Movement Heights:</strong>
          <ul style="margin-bottom: 0;">
            <li><strong>z_approach</strong> = board + 30cm: Safe transit height above all pieces</li>
            <li><strong>z_grasp</strong> = board + 22cm: Height to grasp/release pieces</li>
            <li><strong>z_place</strong> = z_grasp + 0.5cm: Slightly higher when placing to avoid scraping</li>
          </ul>
        </div>

        <div class="code-header"><span>chess_move.py - Node Initialization</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ChessMove(Node):
    """
    Moves a chess piece from one square to another.
    
    Usage:
        ros2 run planning chess_move --from e2 --to e4
    """

    def __init__(self, from_square, to_square):
        super().__init__("chess_move")

        self.chess_coords = ChessCoords(square_size=0.055)  # 5.5cm squares
        self.from_square = from_square
        self.to_square = to_square

        # Subscribe to board center and joint states
        self.subscription_aruco = self.create_subscription(
            PointStamped, "/cube_pose_base_link", self.aruco_callback, 1)
        self.subscription_joints = self.create_subscription(
            JointState, "/joint_states", self.joint_state_callback, 1)

        # Action client for trajectory execution
        self.exec_ac = ActionClient(
            self, FollowJointTrajectory,
            "/scaled_joint_trajectory_controller/follow_joint_trajectory")

        # Service client for gripper control
        self.gripper_cli = self.create_client(Trigger, "/toggle_gripper")

        self.ik_planner = IKPlanner()
        self.job_queue = []  # Sequence of atomic operations</code></pre>

        <h4>Building the Job Queue</h4>
        <p>
          The job queue is a list of atomic operations: either <code>("ik", position)</code> for arm movements or <code>("grip", None)</code> for gripper toggles. Each operation completes before the next begins.
        </p>

        <div class="code-header"><span>chess_move.py - Building the Move Sequence</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def build_job_queue(self, cx, cy, cz):
    """
    Build the 8-step movement sequence.
    cx, cy, cz = board center position from ArUco marker
    """
    # Get square offsets relative to board center
    dx_from, dy_from = self.chess_coords.square_to_offset(self.from_square)
    dx_to, dy_to = self.chess_coords.square_to_offset(self.to_square)

    # Z-heights
    z_approach = cz + 0.30  # Safe transit height
    z_grasp = cz + 0.22     # Grasp height

    # Calculate absolute positions
    from_x, from_y = cx + dx_from, cy + dy_from
    to_x, to_y = cx + dx_to, cy + dy_to

    # Pre-grasp positions (with gripper offset adjustments)
    pg_from = (from_x - 0.01, from_y - 0.08, z_approach)
    pg_to = (to_x - 0.01, to_y - 0.08, z_approach)

    # Build the 8-step sequence
    self.job_queue = [
        ("ik", pg_from),                              # 1. Approach origin
        ("ik", (pg_from[0], pg_from[1], z_grasp)),    # 2. Descend to piece
        ("grip", None),                                # 3. Close gripper
        ("ik", pg_from),                              # 4. Lift piece
        ("ik", pg_to),                                # 5. Transit to destination
        ("ik", (pg_to[0], pg_to[1], z_grasp + 0.005)),# 6. Lower to board
        ("grip", None),                                # 7. Open gripper
        ("ik", pg_to),                                # 8. Retreat upward
    ]</code></pre>

        <h4>Job Execution</h4>
        <p>
          Jobs are executed sequentially. Each IK motion computes joint angles via MoveIt2, then sends the trajectory to the robot's controller. Gripper operations call the <code>/toggle_gripper</code> service.
        </p>

        <div class="code-header"><span>chess_move.py - Sequential Execution</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def execute_jobs(self):
    """Execute jobs one at a time until queue is empty."""
    if not self.job_queue:
        self.get_logger().info("=== CHESS MOVE COMPLETED ===")
        rclpy.shutdown()
        return

    job_type, data = self.job_queue.pop(0)

    if job_type == "ik":
        self.do_ik_motion(data)
    else:
        self.do_grip()

def do_ik_motion(self, pos):
    """Compute IK and execute trajectory to target position."""
    x, y, z = pos

    # Compute IK with gripper pointing down (qy=1.0)
    q = self.ik_planner.compute_ik(
        self.joint_state, x, y, z,
        qx=0.0, qy=1.0, qz=0.0, qw=0.0
    )

    if q is None:
        self.get_logger().error("IK computation failed")
        return

    traj = self.ik_planner.plan_to_joints(q)
    self.execute_trajectory(traj.joint_trajectory)

def do_grip(self):
    """Toggle gripper (open/close)."""
    req = Trigger.Request()
    future = self.gripper_cli.call_async(req)
    rclpy.spin_until_future_complete(self, future)
    self.execute_jobs()  # Continue to next job</code></pre>

        <h3>Capture Moves</h3>
        <p>
          When a piece captures another, we need a <strong>16-step sequence</strong>: first remove the captured piece to an off-board location, then move the attacking piece to the now-empty destination. The <code>ChessTake</code> node handles this two-phase operation.
        </p>

        <div class="code-header"><span>Terminal - Running a Capture</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Capture: piece at e4 takes piece at d5
ros2 run planning chess_take --from e4 --to d5

# With custom off-board position (50cm to the side)
ros2 run planning chess_take --from e4 --to d5 --offboard-y 0.5</code></pre>

        <h4>The 16-Step Capture Sequence</h4>
        <p>
          The capture is split into two phases. Phase 1 removes the captured piece from the board. Phase 2 moves the attacking piece to the destination.
        </p>

        <div class="callout">
          <strong>Phase 1: Remove Captured Piece (Steps 1-8)</strong>
          <ol style="margin-bottom: 0;">
            <li>Approach destination square</li>
            <li>Descend to captured piece</li>
            <li>Grasp captured piece</li>
            <li>Lift piece</li>
            <li>Transit to off-board area</li>
            <li>Lower to off-board surface</li>
            <li>Release captured piece</li>
            <li>Retreat from off-board</li>
          </ol>
        </div>

        <div class="callout">
          <strong>Phase 2: Move Attacking Piece (Steps 9-16)</strong>
          <ol style="margin-bottom: 0;" start="9">
            <li>Approach origin square</li>
            <li>Descend to attacking piece</li>
            <li>Grasp attacking piece</li>
            <li>Lift piece</li>
            <li>Transit to destination</li>
            <li>Lower to board</li>
            <li>Release piece</li>
            <li>Retreat</li>
          </ol>
        </div>

        <div class="code-header"><span>chess_take.py - Node Initialization</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ChessTake(Node):
    """Chess piece capture node using ArUco-calibrated board positions."""

    def __init__(self, from_square, to_square, offset_x=0.0, offset_y=0.0, 
                 offset_z=0.22, offboard_x=0.0, offboard_y=0.5, offboard_z_offset=0.0):
        super().__init__("chess_take")

        self.from_square = from_square.lower()
        self.to_square = to_square.lower()

        # Grasp height offset
        self.offset_z_grasp = offset_z

        # Off-board position for captured pieces (default: 50cm to the side)
        self.offboard_x = offboard_x
        self.offboard_y = offboard_y
        self.offboard_z_offset = offboard_z_offset
        ...

        # Subscribe to calibrated square positions
        self.from_sub = self.create_subscription(
            PointStamped, f'/chess_square/{self.from_square}',
            self.from_square_callback, 1)
        self.to_sub = self.create_subscription(
            PointStamped, f'/chess_square/{self.to_square}',
            self.to_square_callback, 1)

        # Action client and gripper service (same as ChessMove)
        self.exec_ac = ActionClient(self, FollowJointTrajectory,
            "/scaled_joint_trajectory_controller/follow_joint_trajectory")
        self.gripper_cli = self.create_client(Trigger, "/toggle_gripper")

        self.ik_planner = IKPlanner()
        self.job_queue = []</code></pre>

        <h4>Building the Capture Sequence</h4>
        <p>
          The key difference from a regular move is the off-board position where captured pieces are placed. This is configurable via command-line arguments.
        </p>

        <div class="code-header"><span>chess_take.py - 16-Step Capture Sequence</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def build_capture_sequence(self):
    """Build the 16-step capture sequence."""
    from_x, from_y, from_z = self.from_position
    to_x, to_y, to_z = self.to_position

    # Heights
    z_approach = from_z + 0.30
    z_grasp = from_z + self.offset_z_grasp

    # Off-board positions
    offboard_z_grasp = from_z + self.offboard_z_offset + self.offset_z_grasp
    offboard_approach = (self.offboard_x, self.offboard_y, from_z + 0.30)
    offboard_pos = (self.offboard_x, self.offboard_y, offboard_z_grasp)

    # Pre-grasp positions
    pg_to = (to_x, to_y, z_approach)
    pg_from = (from_x, from_y, z_approach)

    self.job_queue = [
        # === PHASE 1: Remove captured piece ===
        ("ik", pg_to),                          # 1. Approach destination
        ("ik", (to_x, to_y, z_grasp)),          # 2. Lower to captured piece
        ("grip", None),                          # 3. Grasp captured piece
        ("ik", pg_to),                          # 4. Lift
        ("ik", offboard_approach),              # 5. Move to off-board
        ("ik", offboard_pos),                   # 6. Lower to surface
        ("grip", None),                          # 7. Release captured piece
        ("ik", offboard_approach),              # 8. Retreat

        # === PHASE 2: Move attacking piece ===
        ("ik", pg_from),                        # 9. Approach origin
        ("ik", (from_x, from_y, z_grasp)),      # 10. Lower to attacker
        ("grip", None),                          # 11. Grasp attacking piece
        ("ik", pg_from),                        # 12. Lift
        ("ik", pg_to),                          # 13. Move to destination
        ("ik", (to_x, to_y, z_grasp + 0.005)),  # 14. Lower to board
        ("grip", None),                          # 15. Release
        ("ik", pg_to),                          # 16. Retreat
    ]</code></pre>

        <h3>Game Replay</h3>
        <p>
          For replaying full games without manually entering each move, we provide a <strong>game file parser</strong> and <strong>replay node</strong>. Users can write moves in a simple notation format, and the system will execute them sequentially with configurable delays between moves.
        </p>

        <h4>Game File Format</h4>
        <p>
          Game files use a simple <code>from-to</code> notation with support for comments. The parser also supports Standard Algebraic Notation (SAN) and PGN format.
        </p>

        <div class="code-header"><span>games/italian_game.txt - Example Game File</span><span>Text</span></div>
<pre class="language-text"><code># Italian Game (Giuoco Piano) Opening
# Comments start with #

# 1. e4 e5
e2-e4
e7-e5

# 2. Nf3 Nc6
g1-f3
b8-c6

# 3. Bc4 Bc5
f1-c4
f8-c5

# 4. Nc3 Nf6
b1-c3
g8-f6

# 5. d3 d6
d2-d3
d7-d6</code></pre>

        <p style="margin-top: 1.5em;">
          To replay a game file, use the <code>chess_game_replay</code> node:
        </p>

        <div class="code-header"><span>Terminal - Running a Game Replay</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Replay a game from file
ros2 run planning chess_game_replay --game-file games/italian_game.txt

# With custom delay between moves (5 seconds)
ros2 run planning chess_game_replay --game-file games/italian_game.txt --delay 5.0</code></pre>

        <h4>Game Parser</h4>
        <p>
          The <code>ChessGameParser</code> reads game files and converts them to a list of <code>(from_square, to_square)</code> tuples. It supports multiple notation formats.
        </p>

        <div class="code-header"><span>chess_game_parser.py - Parsing Game Files</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ChessGameParser:
    """Parse chess game files into move sequences."""

    def parse_game_file(self, filename: str) -> List[Tuple[str, str]]:
        """
        Parse a game file and return list of (from_square, to_square) moves.
        Supports: simple notation (e2-e4), SAN (Nf3), and PGN format.
        """
        with open(filename, 'r') as f:
            content = f.read()

        # Try different parsers in order
        moves = self.parse_simple_notation(content)
        if not moves:
            moves = self.parse_san_notation(content)
        if not moves:
            moves = self.parse_pgn_notation(content)

        return moves

    def parse_simple_notation(self, content: str) -> List[Tuple[str, str]]:
        """Parse simple notation: e2-e4, e2 e4, or e2e4."""
        moves = []

        for line in content.split('\n'):
            line = line.split('#')[0].strip()  # Remove comments
            if not line:
                continue

            # Match patterns: e2-e4, e2 e4, or e2e4
            match = re.match(r'([a-h][1-8])[\s-]*([a-h][1-8])', line)
            if match:
                from_sq, to_sq = match.groups()
                moves.append((from_sq, to_sq))

        return moves if moves else None</code></pre>

        <h4>Game Replay Node</h4>
        <p>
          The <code>ChessGameReplay</code> node loads a game file, subscribes to all required square positions, then executes moves sequentially. It reuses the same 8-step movement sequence as <code>ChessMove</code>.
        </p>

        <div class="code-header"><span>chess_game_replay.py - Replay Node</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">class ChessGameReplay(Node):
    """Replays a chess game from a file."""

    def __init__(self, game_file, offset_x=0.0, offset_y=0.0, offset_z=0.22, delay=3.0):
        super().__init__("chess_game_replay")

        self.move_delay = delay  # Seconds between moves

        # Parse game file
        parser = ChessGameParser()
        self.moves = parser.parse_game_file(game_file)
        self.get_logger().info(f"Loaded {len(self.moves)} moves")

        self.current_move_index = 0
        self.square_positions = {}

        # Subscribe to all squares used in the game
        self._subscribe_to_squares()
        ...

    def _subscribe_to_squares(self):
        """Subscribe to position topics for all squares in the game."""
        squares_needed = set()
        for from_sq, to_sq in self.moves:
            squares_needed.add(from_sq)
            squares_needed.add(to_sq)

        for square in squares_needed:
            self.create_subscription(
                PointStamped,
                f'/chess_square/{square}',
                lambda msg, sq=square: self.square_callback(msg, sq),
                10
            )

    def execute_next_move(self):
        """Execute the next move in the game."""
        if self.current_move_index >= len(self.moves):
            self.get_logger().info("=== GAME REPLAY COMPLETED ===")
            rclpy.shutdown()
            return

        from_sq, to_sq = self.moves[self.current_move_index]
        move_num = self.current_move_index + 1

        self.get_logger().info(f"Move {move_num}/{len(self.moves)}: {from_sq} -> {to_sq}")

        # Get positions and build job queue (same as ChessMove)
        from_pos = self.square_positions[from_sq]
        to_pos = self.square_positions[to_sq]
        self.build_job_queue(from_pos, to_pos)
        self.execute_jobs()

    def execute_jobs(self):
        """Execute jobs sequentially, then move to next game move."""
        if not self.job_queue:
            self.current_move_index += 1
            time.sleep(self.move_delay)  # Pause between moves
            self.execute_next_move()
            return

        job_type, data = self.job_queue.pop(0)
        if job_type == "ik":
            self.do_ik_motion(data)
        else:
            self.do_grip()</code></pre>

        <div class="callout callout-success">
          <strong>Supported Game File Formats:</strong>
          <ul style="margin-bottom: 0;">
            <li><strong>Simple notation:</strong> <code>e2-e4</code>, <code>e2 e4</code>, or <code>e2e4</code></li>
            <li><strong>SAN (Standard Algebraic):</strong> <code>e4</code>, <code>Nf3</code>, <code>Bxc4</code></li>
            <li><strong>PGN format:</strong> <code>1. e4 e5 2. Nf3 Nc6</code></li>
          </ul>
        </div>

        <h3>System Launch File</h3>
        <p>
          To simplify startup, we provide a single launch file that brings up the entire chess system. This includes the camera, ArUco detection, board calibration, MoveIt, and all necessary TF transforms.
        </p>

        <div class="code-header"><span>Terminal - Starting the Chess System</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Launch the complete chess system
ros2 launch planning chess_system.launch.py

# After launch, calibrate the board (run once)
ros2 service call /calibrate_chess_board std_srvs/srv/Trigger

# Execute moves
ros2 run planning chess_move_aruco --from e2 --to e4</code></pre>

        <h4>What the Launch File Starts</h4>
        <p>The launch file orchestrates all components needed for autonomous chess play:</p>

        <div class="code-header"><span>chess_system.launch.py - Complete System Launch</span><span>Python</span></div>
<pre class="language-python"><code class="language-python">def generate_launch_description():

    # 1. USB Camera - Captures live video feed
    camera_launch = IncludeLaunchDescription(
        PythonLaunchDescriptionSource(
            os.path.join(usb_cam_launch_dir, 'camera.launch.py')
        )
    )

    # 2. ArUco Detection Node - Detects markers 100-103 on board corners
    aruco_node = Node(
        package='ros2_aruco',
        executable='aruco_node',
        parameters=[{
            "image_topic": "/camera1/image_raw",
            "camera_info_topic": "/camera1/camera_info",
            "marker_size": 0.05,  # 50mm markers
            "aruco_dictionary_id": "DICT_5X5_250",
        }]
    )

    # 3. Static TF: Links camera frame to robot base_link
    static_camera_to_base = Node(
        package='planning',
        executable='static_tf_transform',
        name='static_tf_marker_to_base',
    )

    # 4. Chess Board Calibrator - Computes all 64 square positions
    chess_calibrator_node = Node(
        package='planning',
        executable='chess_board_calibrator',
    )

    # 5. IK Planner - MoveIt2 interface for trajectory planning
    ik_planner_node = Node(
        package='planning',
        executable='ik',
    )

    # 6. MoveIt Launch - Motion planning framework
    moveit_launch = IncludeLaunchDescription(
        PythonLaunchDescriptionSource(moveit_launch_file),
        launch_arguments={
            "ur_type": "ur7e",
            "launch_rviz": "true"
        }.items(),
    )

    return LaunchDescription([
        camera_launch,              # USB camera
        aruco_node,                 # ArUco detection
        static_camera_to_base,      # TF: camera -> base
        chess_calibrator_node,      # Chess calibrator
        ik_planner_node,            # IK planner
        moveit_launch,              # MoveIt
    ])</code></pre>

        <div class="callout">
          <strong>Key Configuration Points:</strong>
          <ul style="margin-bottom: 0;">
            <li><strong>marker_size:</strong> Set to 0.05m (50mm) to match the physical ArUco markers on your board</li>
            <li><strong>static_tf_transform:</strong> Defines the fixed relationship between the camera and robot base. Adjust if your camera mounting changes.</li>
          </ul>
        </div>

      </section>

      <!-- RESULTS -->
      <section id="results">
        <h2>Results</h2>

        <h3>Demo: Polish Opening</h3>
        <p>
          The following video demonstrates the robot autonomously playing the Polish Opening (1. b4), executing multiple consecutive moves without human intervention.
        </p>
        <figure>
          <iframe width="100%" style="aspect-ratio: 16/9;" src="https://www.youtube.com/embed/16B8934PNmE?rel=0" title="Polish Opening Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          <figcaption>Robot playing the Polish Opening autonomously</figcaption>
        </figure>

        <h3>Demo: Piece Capture</h3>
        <p>
          This video demonstrates the 16-step capture sequence, where a bishop captures a pawn. The robot first removes the captured pawn to an off-board location, then moves the attacking bishop to the now-empty square.
        </p>
        <figure>
          <iframe width="100%" style="aspect-ratio: 16/9;" src="https://www.youtube.com/embed/Uu-hJWIk0lE?rel=0" title="Bishop Captures Pawn" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          <figcaption>Bishop capturing a pawn using the 16-step capture sequence</figcaption>
        </figure>
      </section>

      <!-- CONCLUSION -->
      <section id="conclusion">
        <h2>Conclusion</h2>

        <h3>Summary</h3>
        <p>
          We successfully demonstrated a fully autonomous chess-playing robot capable of playing continuous games with 
          surprisingly little human intervention. The system was able to move all piece types, execute captures (taking 
          opponent pieces off the board), and provide manual control over individual pieces. The ArUco-based calibration 
          system using bilinear interpolation proved robust to camera angle variations and slight board warping.
        </p>

        <h3>Challenges Encountered</h3>
        <ul>
          <li><strong>ArUco Pose Jitter:</strong> The detected poses of ArUco markers were often jittery, causing instability in the computed square positions. This required careful filtering and averaging to stabilize the calibration.</li>
          <li><strong>Gripper Height Tuning:</strong> Finding the correct vertical height offset for grasping required extensive iteration. Too high and the gripper would miss the piece; too low and it would collide with the board.</li>
          <li><strong>Arm Movement Speed:</strong> The robot arm moved quite slowly for safety, but we would have liked to safely increase the speed to improve game pace. Tuning velocity limits without compromising reliability proved difficult.</li>
          <li><strong>Gripper Stickiness:</strong> The gripper and pieces had a tendency to stick together, causing pieces to shift during release. Even when the gripper was centered perfectly over a square, the stickiness would cause pieces to be placed at the edges instead of the center.</li>
        </ul>

        <h3>Limitations & Future Work</h3>
        <div class="callout callout-warning">
          <strong>Current Limitations:</strong>
          <ul style="margin-bottom:0;">
            <li>No piece recognition: system relies on external move commands</li>
            <li>No collision detection with pieces during transit</li>
            <li>Requires manual piece setup at game start</li>
          </ul>
        </div>
        <p><strong>Future Improvements:</strong></p>
        <ul>
          <li>Add computer vision for piece recognition and board state tracking</li>
          <li>Integrate chess engine (Stockfish) for autonomous play against humans</li>
          <li>Add force sensing for grasp verification</li>
          <li>Implement adaptive speed control for faster, safer movements</li>
          <li>Use YOLO object detection to recognize pieces and simplify the move interface, eliminating the need for manual move commands</li>
          <li>Build an intuitive chess UI that allows users to click and drag pieces on a virtual board, with the robot mirroring those moves in real-time</li>
        </ul>
      </section>

      <!-- TEAM -->
      <section id="team">
        <h2>Team</h2>
        <div class="team-grid">
          <div class="team-card">
            <div class="avatar">K</div>
            <h4>Karanbir Sunner</h4>
            <div class="role">Chess System Lead</div>
            <p>Chess migration, game replay, move execution, piece capture, website</p>
          </div>
          <div class="team-card">
            <div class="avatar">M</div>
            <h4>Maanit Sharma</h4>
            <div class="role">TF & Localization Lead</div>
            <p>ArUco pose wrangling, TF relation construction between markers and base link</p>
          </div>
          <div class="team-card">
            <div class="avatar">F</div>
            <h4>Faiaz Khan</h4>
            <div class="role">Manipulation Lead</div>
            <p>Full pipeline for colored cube manipulation and sorting</p>
          </div>
          <div class="team-card">
            <div class="avatar">P</div>
            <h4>Pranav Banwasi</h4>
            <div class="role">Calibration & Presentation</div>
            <p>Chessboard pose calibration, square centers computation, presentation</p>
          </div>
        </div>

        <h3>Detailed Contributions</h3>
        <ul>
          <li><strong>Karanbir Sunner:</strong> Autonomous chess migration, game replay ability, independent chess move abilities, ability to take pieces, website construction</li>
          <li><strong>Pranav Banwasi:</strong> Chessboard pose and square centers calibration, presentation</li>
          <li><strong>Faiaz Khan:</strong> Created full pipeline for colored cube manipulation and sorting</li>
          <li><strong>Maanit Sharma:</strong> Groundlaying work in ArUco pose wrangling, successful TF relation construction between object ArUco tag and base link</li>
        </ul>
      </section>

      <!-- MATERIALS -->
      <section id="materials">
        <h2>Additional Materials</h2>

        <h3>Downloads & Links</h3>
        <div class="links-row">
          <a href="https://github.com/ksunner/ee106a-final-project/tree/working_chess" class="link-card" target="_blank">
            <div class="icon">📦</div>
            <h5>Source Code</h5>
            <p>Full ROS2 workspace</p>
          </a>
          <a href="https://chev.me/arucogen/" class="link-card" target="_blank">
            <div class="icon">📄</div>
            <h5>ArUco Generator</h5>
            <p>Print your own markers</p>
          </a>
          <a href="https://docs.google.com/presentation/d/1Dok4zd8yy1Yrp2GZ8ZX9mwJcRUwXULukosOQNjHbU5Y/edit?usp=sharing" class="link-card" target="_blank">
            <div class="icon">�</div>
            <h5>Presentation Slides</h5>
            <p>Project overview</p>
          </a>
          <a href="https://drive.google.com/drive/folders/1uOGtfID_ZiW0IEVJtwe32_RE-zM9xFGw?usp=drive_link" class="link-card" target="_blank">
            <div class="icon">🎬</div>
            <h5>Demo Videos</h5>
            <p>Google Drive folder</p>
          </a>
        </div>

        <h3>Key Files Reference</h3>
        <div class="table-wrap">
          <table>
            <thead><tr><th>File</th><th>Description</th></tr></thead>
            <tbody>
              <tr><td><code>check_aruco_detection.py</code></td><td>Utility to verify ArUco marker detection is working</td></tr>
              <tr><td><code>chess_coords_aruco.py</code></td><td>Board calibration using ArUco markers + bilinear interpolation</td></tr>
              <tr><td><code>chess_game_parser.py</code></td><td>Parses game files in simple, SAN, and PGN notation formats</td></tr>
              <tr><td><code>chess_game_replay.py</code></td><td>Replay full games from move files</td></tr>
              <tr><td><code>chess_move_aruco.py</code></td><td>Single move execution with IK planning</td></tr>
              <tr><td><code>ik.py</code></td><td>MoveIt2 IK interface and trajectory planning</td></tr>
              <tr><td><code>chess_system.launch.py</code></td><td>Complete system launch file</td></tr>
            </tbody>
          </table>
        </div>

        <h3>Quick Start Commands</h3>
        <div class="code-header"><span>Terminal</span><span>Bash</span></div>
<pre class="language-bash"><code class="language-bash"># Build the workspace
cd ~/ros_workspaces/ee106a-final-project/final_project
colcon build
source install/setup.bash

# Launch the complete system
ros2 launch planning chess_system.launch.py

# Calibrate the board (run once)
ros2 service call /calibrate_chess_board std_srvs/srv/Trigger

# Execute a single move
ros2 run planning chess_move_aruco --from e2 --to e4

# Replay a full game
ros2 run planning chess_game_replay --game-file games/ladder_checkmate.txt</code></pre>

        <h3>Dependencies</h3>
        <ul>
          <li>ROS2 Humble</li>
          <li>MoveIt2</li>
          <li>OpenCV 4.7+ (with ArUco module)</li>
          <li>NumPy, PyYAML</li>
          <li>Universal Robots ROS2 Driver</li>
        </ul>
      </section>
    </main>
  </div>

  <footer>
    EE106A: Introduction to Robotics · UC Berkeley · Fall 2025<br>
    <a href="https://github.com/ksunner/ee106a-final-project/tree/working_chess">GitHub Repository</a>
  </footer>

  <script>
    // Highlight active TOC link on scroll
    const links = Array.from(document.querySelectorAll('#toc a'));
    const sections = links.map(a => document.querySelector(a.getAttribute('href')));
    
    function updateActiveLink() {
      let current = '';
      sections.forEach((section, i) => {
        if (section) {
          const rect = section.getBoundingClientRect();
          // Section is active if its top is above 30% of viewport
          if (rect.top <= window.innerHeight * 0.3) {
            current = links[i].getAttribute('href');
          }
        }
      });
      links.forEach(link => {
        link.classList.toggle('active', link.getAttribute('href') === current);
      });
    }
    
    window.addEventListener('scroll', updateActiveLink);
    updateActiveLink(); // Initial call
  </script>
</body>
</html>
